# Here you can define all your data sets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://kedro.readthedocs.io/en/stable/05_data/01_data_catalog.html
#
# We support interacting with a variety of data stores including local file systems, cloud, network and HDFS
#
# An example data set definition can look as follows:
#
#bikes:
#  type: pandas.CSVDataSet
#  filepath: "data/01_raw/bikes.csv"
#
#weather:
#  type: spark.SparkDataSet
#  filepath: s3a://your_bucket/data/01_raw/weather*
#  file_format: csv
#  credentials: dev_s3
#  load_args:
#    header: True
#    inferSchema: True
#  save_args:
#    sep: '|'
#    header: True
#
#scooters:
#  type: pandas.SQLTableDataSet
#  credentials: scooters_credentials
#  table_name: scooters
#  load_args:
#    index_col: ['name']
#    columns: ['name', 'gear']
#  save_args:
#    if_exists: 'replace'
#    # if_exists: 'fail'
#    # if_exists: 'append'
#
# The Data Catalog supports being able to reference the same file using two different DataSet implementations
# (transcoding), templating and a way to reuse arguments that are frequently repeated. See more here:
# https://kedro.readthedocs.io/en/stable/05_data/01_data_catalog.html
#
# This is a data set used by the "Hello World" example pipeline provided with the project
# template. Please feel free to remove it once you remove the example pipeline.

####
# Vipin20 Dataset
###
vipin20_kaggle_data:
  type: pandas.CSVDataSet
  filepath: s3://hsv-ai/product-recommendation/data/01_raw/vipin20/transaction_data.csv
  credentials: aws

vipin20_transactions:
  type: pandas.CSVDataSet
  filepath: data/05_model_input/vipin20/transactions.csv

vipin20_products:
  type: pandas.CSVDataSet
  filepath: data/05_model_input/vipin20/products.csv

vipin20_user_factors:
  type: pickle.PickleDataSet
  filepath: data/06_models/vipin20/user_factors.pkl

vipin20_item_factors:
  type: pickle.PickleDataSet
  filepath: data/06_models/vipin20/item_factors.pkl

vipin20_product_train:
  type: pickle.PickleDataSet
  filepath: data/06_models/vipin20/product_train.pkl

###
# ecommerce dataset
###
ecommerce_kaggle_data:
  type: pandas.CSVDataSet
  filepath: s3://hsv-ai/product-recommendation/data/01_raw/ecommerce/data.csv
  credentials: aws
  load_args:
    encoding: 'iso-8859-1'

ecommerce_transactions:
  type: pandas.CSVDataSet
  filepath: data/05_model_input/ecommerce/transactions.csv

ecommerce_products:
  type: pandas.CSVDataSet
  filepath: data/05_model_input/ecommerce/products.csv

ecommerce_user_factors:
  type: pickle.PickleDataSet
  filepath: data/06_models/ecommerce/user_factors.pkl

ecommerce_item_factors:
  type: pickle.PickleDataSet
  filepath: data/06_models/ecommerce/item_factors.pkl

ecommerce_product_train:
  type: pickle.PickleDataSet
  filepath: data/06_models/ecommerce/product_train.pkl

###
# jewelry dataset
###
jewelry_kaggle_data:
  type: pandas.CSVDataSet
  filepath: s3://hsv-ai/product-recommendation/data/01_raw/jewelry/jewelry.csv
  credentials: aws

jewelry_transactions:
  type: pandas.CSVDataSet
  filepath: data/05_model_input/jewelry/transactions.csv

jewelry_products:
  type: pandas.CSVDataSet
  filepath: data/05_model_input/jewelry/products.csv

jewelry_user_factors:
  type: pickle.PickleDataSet
  filepath: data/06_models/jewelry/user_factors.pkl

jewelry_item_factors:
  type: pickle.PickleDataSet
  filepath: data/06_models/jewelry/item_factors.pkl

jewelry_product_train:
  type: pickle.PickleDataSet
  filepath: data/06_models/jewelry/product_train.pkl

###
# ecommerce dataset
###
ecommerce_kaggle_data:
  type: pandas.CSVDataSet
  filepath: s3://hsv-ai/product-recommendation/data/01_raw/ecommerce/data.csv
  credentials: aws
  load_args:
    encoding: 'iso-8859-1'

ecommerce_transactions:
  type: pandas.CSVDataSet
  filepath: data/05_model_input/ecommerce/transactions.csv

ecommerce_products:
  type: pandas.CSVDataSet
  filepath: data/05_model_input/ecommerce/products.csv

ecommerce_user_factors:
  type: pickle.PickleDataSet
  filepath: data/06_models/ecommerce/user_factors.pkl

ecommerce_item_factors:
  type: pickle.PickleDataSet
  filepath: data/06_models/ecommerce/item_factors.pkl

ecommerce_product_train:
  type: pickle.PickleDataSet
  filepath: data/06_models/ecommerce/product_train.pkl

###
# journey dataset
###
journey_kaggle_transaction_data:
  type: pandas.CSVDataSet
  filepath: s3://hsv-ai/product-recommendation/data/01_raw/journey/transaction_data.csv
  credentials: aws

journey_kaggle_product_data:
  type: pandas.CSVDataSet
  filepath: s3://hsv-ai/product-recommendation/data/01_raw/journey/product.csv
  credentials: aws

journey_transactions:
  type: pandas.CSVDataSet
  filepath: data/05_model_input/journey/transactions.csv

journey_products:
  type: pandas.CSVDataSet
  filepath: data/05_model_input/journey/products.csv

journey_user_factors:
  type: pickle.PickleDataSet
  filepath: data/06_models/journey/user_factors.pkl

journey_item_factors:
  type: pickle.PickleDataSet
  filepath: data/06_models/journey/item_factors.pkl

journey_product_train:
  type: pickle.PickleDataSet
  filepath: data/06_models/journey/product_train.pkl

###
# electronics dataset
###
electronics_kaggle_data:
  type: pandas.CSVDataSet
  filepath: s3://hsv-ai/product-recommendation/data/01_raw/electronics/kz.csv
  credentials: aws

electronics_transactions:
  type: pandas.CSVDataSet
  filepath: data/05_model_input/electronics/transactions.csv

electronics_products:
  type: pandas.CSVDataSet
  filepath: data/05_model_input/electronics/products.csv

electronics_user_factors:
  type: pickle.PickleDataSet
  filepath: data/06_models/electronics/user_factors.pkl

electronics_item_factors:
  type: pickle.PickleDataSet
  filepath: data/06_models/electronics/item_factors.pkl

electronics_product_train:
  type: pickle.PickleDataSet
  filepath: data/06_models/electronics/product_train.pkl
