{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gEfZf48Wu5f0"
   },
   "source": [
    "![HSV-AI Logo](https://github.com/HSV-AI/hugo-website/blob/master/static/images/logo_v9.png?raw=true)\n",
    "\n",
    "# Implicit Recommendation from ECommerce Data\n",
    "\n",
    "Some of the material for this work is based on [A Gentle Introduction to Recommender Systems with Implicit Feedback](https://jessesw.com/Rec-System/) by Jesse Steinweg Woods. This tutorial includes an implementation of the Alternating Least Squares algorithm and some other useful functions (like the area under the curve calculation). Other parts of the tutorial are based on a previous version of the Implicit library and had to be reworked.\n",
    "\n",
    "The dataset used for this work is from Kaggle [Vipin Kumar Transaction Data](https://www.kaggle.com/vipin20/transaction-data):\n",
    "\n",
    "## Context\n",
    "\n",
    "This is a item purchased transactions data. It has 8 columns.\n",
    "This data makes you familer with transactions data.\n",
    "\n",
    "## Content\n",
    "\n",
    "Data description is :-\n",
    "\n",
    "* UserId -It is a unique ID for all User Id\n",
    "* TransactionId -It contains unique Transactions ID\n",
    "* TransactionTime -It contains Transaction Time\n",
    "* ItemCode -It contains item code that item will be purchased\n",
    "* ItemDescription -It contains Item description\n",
    "* NumberOfItemPurchased -It contains total number of items Purchased\n",
    "* CostPerltem -Cost per item Purchased\n",
    "* Country -Country where item purchased\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OApEEC0_wB4C"
   },
   "source": [
    "# Global Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fsb9emt6nrPu"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import implicit\n",
    "import scipy\n",
    "from sklearn import metrics\n",
    "from pandas.api.types import CategoricalDtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implicit Recommendation Model\n",
    "\n",
    "The code below creates and trains one of the models available from the Implicit package. Currently using hyperparameters suggested by various tutorials with no tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 29\n",
    "factors = 64\n",
    "regularization = 0.117\n",
    "iterations = 73\n",
    "\n",
    "model = implicit.als.AlternatingLeastSquares(factors=factors,\n",
    "                                    regularization=regularization,\n",
    "                                    iterations=iterations)\n",
    "\n",
    "user_vecs = np.load('../data/interim/vipin20/user_factors.npy')\n",
    "item_vecs = np.load('../data/interim/vipin20/item_factors.npy')\n",
    "\n",
    "model.user_factors = user_vecs\n",
    "model.item_factors = item_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./Common-Functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./vipin20-Transaction-Data-EDA.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_train, product_test, products_altered, transactions_altered = make_train(purchases_sparse, pct_test = 0.211)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring the Model\n",
    "\n",
    "Following the tutorial, we will use the area under the Receiver Operating Characteristic curve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, popular = calc_mean_auc(product_train, products_altered, \n",
    "              [scipy.sparse.csr_matrix(item_vecs), scipy.sparse.csr_matrix(user_vecs.T)], product_test)\n",
    "\n",
    "print('Our model scored',test,'versus a score of',popular,'if we always recommended the most popular item.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spot Checking\n",
    "\n",
    "Now that we have a pretty good idea of the model performance overall, we can spot check a few things like finding similar items and checking item recommendations for an existing invoice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_lookup = transactions[['ItemCode', 'ItemDescription']].drop_duplicates() # Only get unique item/description pairs\n",
    "item_lookup['ItemCode'] = item_lookup.ItemCode.astype(str) # Encode as strings for future lookup ease\n",
    "\n",
    "price_lookup = transactions[['ItemCode', 'CostPerItem']].drop_duplicates() # Only get unique item/description pairs\n",
    "price_lookup['ItemCode'] = price_lookup.ItemCode.astype(str) # Encode as strings for future lookup ease\n",
    "\n",
    "related = model.similar_items(1284)\n",
    "for rel in related:\n",
    "    index = rel[0]\n",
    "    prob = rel[1]\n",
    "    item = item_lookup[item_lookup.ItemCode == str(item_list[index])].values\n",
    "    print(prob, item[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_items = (product_train * alpha).astype('double').T.tocsr()\n",
    "def recommend(order):\n",
    "    print('Order Contents:')\n",
    "    print(transactions[transactions.TransactionId == transaction_list[order]].loc[:, ['ItemCode', 'ItemDescription']])\n",
    "    print('Recommendations:')\n",
    "    recommendations = model.recommend(order, user_items)\n",
    "    for rec in recommendations:\n",
    "        index = rec[0]\n",
    "        prob = rec[1]\n",
    "        stock_code = item_list[index]\n",
    "        item = item_lookup[item_lookup.ItemCode == str(item_list[index])].values\n",
    "        print(prob, stock_code, item[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions['ItemTotal'] = transactions['NumberOfItemsPurchased'] * transactions['CostPerItem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_price = []\n",
    "for user in transactions_altered:\n",
    "    recommendations = model.recommend(user, user_items)\n",
    "    index = recommendations[0][0]\n",
    "    price = price_lookup[price_lookup.ItemCode == str(item_list[index])].values\n",
    "    item = item_lookup[item_lookup.ItemCode == str(item_list[index])].values\n",
    "    recommended_price.append(price[0][1])\n",
    "    \n",
    "total_recommended = np.sum(recommended_price)\n",
    "\n",
    "print('After recommending',len(transactions_altered),'items, there would be an increase of',\n",
    "      \"${:,.2f}\".format(total_recommended*test),'in additional purchases.')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of ECommerce-recommendation",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
