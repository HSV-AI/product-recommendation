{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gEfZf48Wu5f0"
   },
   "source": [
    "![HSV-AI Logo](https://github.com/HSV-AI/hugo-website/blob/master/static/images/logo_v9.png?raw=true)\n",
    "\n",
    "# Implicit Recommendation from ECommerce Data\n",
    "\n",
    "Some of the material for this work is based on [A Gentle Introduction to Recommender Systems with Implicit Feedback](https://jessesw.com/Rec-System/) by Jesse Steinweg Woods. This tutorial includes an implementation of the Alternating Least Squares algorithm and some other useful functions (like the area under the curve calculation). Other parts of the tutorial are based on a previous version of the Implicit library and had to be reworked.\n",
    "\n",
    "The dataset used for this work is from Kaggle [E-Commerce Data, Actual transactions from UK retailer](https://www.kaggle.com/carrie1/ecommerce-data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OApEEC0_wB4C"
   },
   "source": [
    "# Global Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fsb9emt6nrPu"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'implicit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c452df728587>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mimplicit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'implicit'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import implicit\n",
    "import scipy\n",
    "from sklearn import metrics\n",
    "from pandas.api.types import CategoricalDtype\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFdmU2CswOP-"
   },
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "i0YcK8s4nt6L",
    "outputId": "d92b409a-8506-4e70-da9f-78bf52b328a1"
   },
   "outputs": [],
   "source": [
    "# It appears that the csv file is encoded as iso-8859-1 (I guessed) and has to be loaded using the encoding parameter.\n",
    "df = pd.read_csv('../data/external/ecommerce/data.csv', encoding='iso-8859-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Unique invoices', len(pd.unique(df['InvoiceNo'])))\n",
    "print('Unique products', len(pd.unique(df['StockCode'])))\n",
    "print('Total rows', len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for missing values\n",
    "\n",
    "It looks like the InvoiceNo, StockCode, and Quantity are always available. That is all that we will be using from this dataset, so the rest is fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xp51kFzvhhxG",
    "outputId": "b3fa307b-736a-4de1-d16d-fad380e9d27c"
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uS1WtSjzmgYW"
   },
   "source": [
    "Let's look at the number of products and see how they are distributed among the orders. We can use the value_counts method from pandas to get an idea of how often each product is ordered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 371
    },
    "id": "NxhZYm-NoDXf",
    "outputId": "cd447f54-ec73-4806-b385-2aa74a0240df"
   },
   "outputs": [],
   "source": [
    "product_counts = df['StockCode'].value_counts().to_numpy()\n",
    "print('There are', len(product_counts), 'unique products\\n')\n",
    "print('Here are the counts of products ordered from largest to smallest')\n",
    "print(product_counts)\n",
    "print('\\nAnd a graph of what the curve looks like:')\n",
    "plt.plot(product_counts) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that there are a few items in the store that sell a LOT, and most that are sold a few times. This seems normal for a retail store. Let's take a quick look at the most purchased item to see if it makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0DhAue9MadsG",
    "outputId": "656f66b1-6fd6-442e-f176-c2cd9d6688a4"
   },
   "outputs": [],
   "source": [
    "df['StockCode'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['StockCode']=='85123A'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't have information about the market of the retail store, but looking at a price of 2.55 - this looks like a normal high volume item.\n",
    "\n",
    "Now we can check the value of each invoice and see what jumps out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "9qd6mg9t2-Ud",
    "outputId": "fae68a3d-58a0-4ae2-89f4-4ba7d21e8b1e"
   },
   "outputs": [],
   "source": [
    "df['StockTotal'] = df['Quantity'] * df['UnitPrice']\n",
    "totals = df.groupby(df.InvoiceNo)['StockTotal'].sum()\n",
    "totals.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well there's something worth looking into. We need to figure out what the negative order totals are. It would have to be either a negative quantity or price - so let's figure out which it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are', len(df[df.Quantity < 0]), 'negative quantities')\n",
    "df[df.Quantity < 0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to figure out what to do with these. We could throw out all invoices that include negative quanties, or just the items with negative quanties. Let's check to see if we have any mixed invoices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df.groupby(df.InvoiceNo).agg(minQ=('Quantity', 'min'), \n",
    "                               maxQ=('Quantity', 'max'))\n",
    "temp_df[(temp_df.minQ < 0) & (temp_df.maxQ > 0)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that all negative quantities are on invoices with no purchases, we should be able to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are', len(df[df.UnitPrice < 0]), 'negative unit prices')\n",
    "\n",
    "df[df.UnitPrice < 0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we can throw out anything with a negative UnitPrice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df.UnitPrice > 0) & (df.Quantity > 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to look into those very large sums on the invoice total to see what is happening there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totals.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.InvoiceNo == '541431'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eAr75-G33l8o"
   },
   "source": [
    "It looks like these were actual orders with a giant quantity. These aren't your average customers, so we may need to try both with the data and without.\n",
    "\n",
    "Another thing we can do is compute the sparsity of the data. This is useful to see if there is enough overlap between the orders and products to make a useful decision for recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5aoGeTmPq55e",
    "outputId": "68bc7cdb-9005-4264-9407-3e8596f51f0d"
   },
   "outputs": [],
   "source": [
    "order_counts = df['InvoiceNo'].value_counts()\n",
    "num_orders = len(order_counts)\n",
    "num_items = len(product_counts)\n",
    "sparsity = 1 - len(df) / (num_orders * num_items)\n",
    "print(f'number of orders: {num_orders}, number of items: {num_items}')\n",
    "print(f'matrix sparsity: {sparsity:f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "To62Zd83tJ4f"
   },
   "source": [
    "Compare that with the 100k movielens dataset that has:\n",
    "\n",
    "```\n",
    "number of users: 943, number of items: 1682\n",
    "matrix sparsity: 0.936953\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NjTFgyUryB6E"
   },
   "source": [
    "Given that this is intended to be used for recommendations based in individual orders, we can remove any invoice that has less than 2 items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qZKx1mQYoUH9",
    "outputId": "996cf8cd-6446-4aef-bd21-37329c500d2d"
   },
   "outputs": [],
   "source": [
    "minimum_order_size = 2\n",
    "order_group = df.loc[:, ['InvoiceNo', 'StockCode']].groupby('InvoiceNo').count()\n",
    " \n",
    "multi_order = order_group[(order_group.StockCode >= minimum_order_size)].count()\n",
    "single_order = order_group[(order_group.StockCode < minimum_order_size)].count()\n",
    " \n",
    "print('Orders with at least',minimum_order_size,'products:',multi_order['StockCode'])\n",
    "print('Orders with less than',minimum_order_size,'products:',single_order['StockCode'])\n",
    " \n",
    "# We can capture the list of mutiple product orders with this:\n",
    "order_filter = order_group[(order_group.StockCode >= minimum_order_size)].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L42LelQPrcHl",
    "outputId": "3954ac42-00b0-478c-c9b6-b3dae71be194"
   },
   "outputs": [],
   "source": [
    "filtered_df = df[df['InvoiceNo'].isin(order_filter)].copy()\n",
    "print('Original dataframe length:', len(df))\n",
    "print('Filtered dataframe length:', len(filtered_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 371
    },
    "id": "yWQoVWQu8p_Y",
    "outputId": "3035200f-4db0-4155-f4ef-0e24d85748d3"
   },
   "outputs": [],
   "source": [
    "product_counts = filtered_df['StockCode'].value_counts().to_numpy()\n",
    "print('There are', len(product_counts), 'unique products\\n')\n",
    "print('\\nAnd a graph of what the curve looks like:')\n",
    "plt.plot(product_counts) \n",
    "plt.show()\n",
    " \n",
    "order_counts = filtered_df['InvoiceNo'].value_counts()\n",
    "num_orders = len(order_counts)\n",
    "num_items = len(product_counts)\n",
    "sparsity = 1 - len(df) / (num_orders * num_items)\n",
    "print(f'number of orders: {num_orders}, number of items: {num_items}')\n",
    "print(f'matrix sparsity: {sparsity:f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N5-NsL0CieG1"
   },
   "outputs": [],
   "source": [
    "filtered_df['StockCode'] = filtered_df['StockCode'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_lookup = filtered_df[['StockCode', 'Description']].drop_duplicates() # Only get unique item/description pairs\n",
    "item_lookup['StockCode'] = item_lookup.StockCode.astype(str) # Encode as strings for future lookup ease\n",
    "\n",
    "price_lookup = filtered_df[['StockCode', 'UnitPrice']].drop_duplicates()\n",
    "price_lookup['StockCode'] = price_lookup.StockCode.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "id": "LXNnCGvPle4m",
    "outputId": "830b15f6-1573-4f4c-aaf6-b60e564c2c0e"
   },
   "outputs": [],
   "source": [
    "selected_df = filtered_df[['InvoiceNo', 'StockCode', 'Quantity']]\n",
    "selected_df.info()\n",
    "selected_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoices = list(np.sort(selected_df.InvoiceNo.unique())) # Get our unique customers\n",
    "products = list(selected_df.StockCode.unique()) # Get our unique products that were purchased\n",
    "quantity = list(selected_df.Quantity) # All of our purchases\n",
    "\n",
    "cols = selected_df.InvoiceNo.astype(CategoricalDtype(categories=invoices, ordered=True)).cat.codes \n",
    "# Get the associated row indices\n",
    "rows = selected_df.StockCode.astype(CategoricalDtype(categories=products, ordered=True)).cat.codes \n",
    "# Get the associated column indices\n",
    "purchases_sparse = scipy.sparse.csr_matrix((quantity, (rows, cols)), shape=(len(products), len(invoices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(purchases_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_size = purchases_sparse.shape[0]*purchases_sparse.shape[1] # Number of possible interactions in the matrix\n",
    "num_purchases = len(purchases_sparse.nonzero()[0]) # Number of items interacted with\n",
    "sparsity = 100*(1 - (num_purchases/matrix_size))\n",
    "sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & Test Datasets\n",
    "\n",
    "We will use the function below to create a training and test dataset from the tutorial linked at the top. The test dataset masks some percentage of purchases to tested later with a recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train(ratings, pct_test = 0.2):\n",
    "    '''\n",
    "    This function will take in the original user-item matrix and \"mask\" a percentage of the original ratings where a\n",
    "    user-item interaction has taken place for use as a test set. The test set will contain all of the original ratings, \n",
    "    while the training set replaces the specified percentage of them with a zero in the original ratings matrix. \n",
    "    \n",
    "    parameters: \n",
    "    \n",
    "    ratings - the original ratings matrix from which you want to generate a train/test set. Test is just a complete\n",
    "    copy of the original set. This is in the form of a sparse csr_matrix. \n",
    "    \n",
    "    pct_test - The percentage of user-item interactions where an interaction took place that you want to mask in the \n",
    "    training set for later comparison to the test set, which contains all of the original ratings. \n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    training_set - The altered version of the original data with a certain percentage of the user-item pairs \n",
    "    that originally had interaction set back to zero.\n",
    "    \n",
    "    test_set - A copy of the original ratings matrix, unaltered, so it can be used to see how the rank order \n",
    "    compares with the actual interactions.\n",
    "    \n",
    "    user_inds - From the randomly selected user-item indices, which user rows were altered in the training data.\n",
    "    This will be necessary later when evaluating the performance via AUC.\n",
    "    '''\n",
    "    test_set = ratings.copy() # Make a copy of the original set to be the test set. \n",
    "    test_set[test_set != 0] = 1 # Store the test set as a binary preference matrix\n",
    "    training_set = ratings.copy() # Make a copy of the original data we can alter as our training set. \n",
    "    nonzero_inds = training_set.nonzero() # Find the indices in the ratings data where an interaction exists\n",
    "    nonzero_pairs = list(zip(nonzero_inds[0], nonzero_inds[1])) # Zip these pairs together of user,item index into list\n",
    "    random.seed(0) # Set the random seed to zero for reproducibility\n",
    "    num_samples = int(np.ceil(pct_test*len(nonzero_pairs))) # Round the number of samples needed to the nearest integer\n",
    "    samples = random.sample(nonzero_pairs, num_samples) # Sample a random number of user-item pairs without replacement\n",
    "    user_inds = [index[0] for index in samples] # Get the user row indices\n",
    "    item_inds = [index[1] for index in samples] # Get the item column indices\n",
    "    training_set[user_inds, item_inds] = 0 # Assign all of the randomly chosen user-item pairs to zero\n",
    "    training_set.eliminate_zeros() # Get rid of zeros in sparse array storage after update to save space\n",
    "    return training_set, test_set, list(set(user_inds)) # Output the unique list of user rows that were altered  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_train, product_test, product_users_altered = make_train(purchases_sparse, pct_test = 0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implicit Recommendation Model\n",
    "\n",
    "The code below creates and trains one of the models available from the Implicit package. Currently using hyperparameters suggested by various tutorials with no tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 15\n",
    "\n",
    "model = implicit.als.AlternatingLeastSquares(factors=64,\n",
    "                                    regularization=0.1,\n",
    "                                    iterations=50,\n",
    "                                    use_native=False)\n",
    "\n",
    "## BayesianPersonalizedRanking was pretty bad\n",
    "# model = implicit.bpr.BayesianPersonalizedRanking(factors=31,\n",
    "#                                     regularization=0.1,\n",
    "#                                     iterations=50)\n",
    "\n",
    "\n",
    "# model = implicit.lmf.LogisticMatrixFactorization(factors=32,\n",
    "#                                     regularization=0.1,\n",
    "#                                     iterations=50)\n",
    "\n",
    "model.fit((product_train * alpha).astype('double'))\n",
    "\n",
    "user_vecs = model.user_factors\n",
    "item_vecs = model.item_factors\n",
    "\n",
    "# Deprecated function below\n",
    "# user_vecs, item_vecs = implicit.alternating_least_squares((product_train*alpha).astype('double'), \n",
    "#                                                           factors=32, \n",
    "#                                                           regularization = 0.1, \n",
    "#                                                           iterations = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring the Model\n",
    "\n",
    "Following the tutorial, we will use the area under the Receiver Operating Characteristic curve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_score(predictions, test):\n",
    "    '''\n",
    "    This simple function will output the area under the curve using sklearn's metrics. \n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    - predictions: your prediction output\n",
    "    \n",
    "    - test: the actual target result you are comparing to\n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    - AUC (area under the Receiver Operating Characterisic curve)\n",
    "    '''\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test, predictions)\n",
    "    return metrics.auc(fpr, tpr)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean_auc(training_set, altered_users, predictions, test_set):\n",
    "    '''\n",
    "    This function will calculate the mean AUC by user for any user that had their user-item matrix altered. \n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    training_set - The training set resulting from make_train, where a certain percentage of the original\n",
    "    user/item interactions are reset to zero to hide them from the model \n",
    "    \n",
    "    predictions - The matrix of your predicted ratings for each user/item pair as output from the implicit MF.\n",
    "    These should be stored in a list, with user vectors as item zero and item vectors as item one. \n",
    "    \n",
    "    altered_users - The indices of the users where at least one user/item pair was altered from make_train function\n",
    "    \n",
    "    test_set - The test set constucted earlier from make_train function\n",
    "    \n",
    "    \n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    The mean AUC (area under the Receiver Operator Characteristic curve) of the test set only on user-item interactions\n",
    "    there were originally zero to test ranking ability in addition to the most popular items as a benchmark.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    store_auc = [] # An empty list to store the AUC for each user that had an item removed from the training set\n",
    "    popularity_auc = [] # To store popular AUC scores\n",
    "    pop_items = np.array(test_set.sum(axis = 0)).reshape(-1) # Get sum of item iteractions to find most popular\n",
    "    item_vecs = predictions[1]\n",
    "    for user in altered_users: # Iterate through each user that had an item altered\n",
    "        training_row = training_set[user,:].toarray().reshape(-1) # Get the training set row\n",
    "        zero_inds = np.where(training_row == 0) # Find where the interaction had not yet occurred\n",
    "        # Get the predicted values based on our user/item vectors\n",
    "        user_vec = predictions[0][user,:]\n",
    "        pred = user_vec.dot(item_vecs).toarray()[0,zero_inds].reshape(-1)\n",
    "        # Get only the items that were originally zero\n",
    "        # Select all ratings from the MF prediction for this user that originally had no iteraction\n",
    "        actual = test_set[user,:].toarray()[0,zero_inds].reshape(-1) \n",
    "        # Select the binarized yes/no interaction pairs from the original full data\n",
    "        # that align with the same pairs in training \n",
    "        pop = pop_items[zero_inds] # Get the item popularity for our chosen items\n",
    "        store_auc.append(auc_score(pred, actual)) # Calculate AUC for the given user and store\n",
    "        popularity_auc.append(auc_score(pop, actual)) # Calculate AUC using most popular and score\n",
    "    # End users iteration\n",
    "    \n",
    "    return float('%.3f'%np.mean(store_auc)), float('%.3f'%np.mean(popularity_auc))  \n",
    "   # Return the mean AUC rounded to three decimal places for both test and popularity benchmark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, popular = calc_mean_auc(product_train, product_users_altered, \n",
    "              [scipy.sparse.csr_matrix(item_vecs), scipy.sparse.csr_matrix(user_vecs.T)], product_test)\n",
    "\n",
    "print('Our model scored',test,'versus a score of',popular,'if we always recommended the most popular item.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_price = []\n",
    "for user in product_users_altered:\n",
    "    recommendations = model.recommend(user, user_items)\n",
    "    index = recommendations[0][0]\n",
    "    price = price_lookup[price_lookup.StockCode == products[index]].values\n",
    "    recommended_price.append(price[0][1])\n",
    "    \n",
    "total_recommended = np.sum(recommended_price)\n",
    "\n",
    "print('After recommending',len(product_users_altered),'items, there would be an increase of',\n",
    "      \"${:,.2f}\".format(total_recommended*test),'in additional purchases.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recommended_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spot Checking\n",
    "\n",
    "Now that we have a pretty good idea of the model performance overall, we can spot check a few things like finding similar items and checking item recommendations for an existing invoice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "related = model.similar_items(1284)\n",
    "for rel in related:\n",
    "    index = rel[0]\n",
    "    prob = rel[1]\n",
    "    item = item_lookup[item_lookup.StockCode == products[index]].values\n",
    "    print(prob, item[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_items = (product_train * alpha).astype('double').T.tocsr()\n",
    "def recommend(order):\n",
    "    print('Order Contents:')\n",
    "    print(filtered_df[filtered_df.InvoiceNo == invoices[order]].loc[:, ['StockCode', 'Description']])\n",
    "    print('Recommendations:')\n",
    "    recommendations = model.recommend(order, user_items)\n",
    "    for rec in recommendations:\n",
    "        index = rec[0]\n",
    "        prob = rec[1]\n",
    "        stock_code = products[index]\n",
    "        item = item_lookup[item_lookup.StockCode == stock_code].values\n",
    "        print(prob, stock_code, item[0][1])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend(8889)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F Score\n",
    "\n",
    "Keeping this down here in case we want to compute F Score to go along with AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aOSjX_t8gF1h"
   },
   "outputs": [],
   "source": [
    "def get_f_score(precision, recall):\n",
    "  denominator = precision + recall\n",
    "  if(denominator == 0):\n",
    "    return 0\n",
    "  return 2 * (precision * recall) / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E55Bi-RgsbVZ"
   },
   "outputs": [],
   "source": [
    "def precision_recall_at_k(predictions, k=10, threshold=.75):\n",
    "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        # When n_rec_k is 0, Precision is undefined. We here set it to 0.\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        # When n_rel is 0, Recall is undefined. We here set it to 0.\n",
    "\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "\n",
    "    return precisions, recalls"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of ECommerce-recommendation",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
