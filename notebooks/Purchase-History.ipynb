{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gEfZf48Wu5f0"
   },
   "source": [
    "![HSV-AI Logo](https://github.com/HSV-AI/hugo-website/blob/master/static/images/logo_v9.png?raw=true)\n",
    "\n",
    "[Dataset](https://www.kaggle.com/mkechinov/ecommerce-purchase-history-from-electronics-store)\n",
    "\n",
    "This file contains purchase data from April 2020 to November 2020 from a large home appliances and electronics online store.\n",
    "\n",
    "Each row in the file represents an event. All events are related to products and users. Each event is like many-to-many relation between products and users.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OApEEC0_wB4C"
   },
   "source": [
    "# Global Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fsb9emt6nrPu"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFdmU2CswOP-"
   },
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "i0YcK8s4nt6L",
    "outputId": "d92b409a-8506-4e70-da9f-78bf52b328a1"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/external/kz.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for missing values\n",
    "\n",
    "It looks like the order and product id are always available. That is all that we will be using from this dataset, to the rest is fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xp51kFzvhhxG",
    "outputId": "b3fa307b-736a-4de1-d16d-fad380e9d27c"
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uS1WtSjzmgYW"
   },
   "source": [
    "Let's look at the number of products and see how they are distributed among the orders. We can use the value_counts method from pandas to get an idea of how often each product is ordered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 371
    },
    "id": "NxhZYm-NoDXf",
    "outputId": "cd447f54-ec73-4806-b385-2aa74a0240df"
   },
   "outputs": [],
   "source": [
    "product_counts = df['product_id'].value_counts().to_numpy()\n",
    "print('There are', len(product_counts), 'unique products\\n')\n",
    "print('Here are the counts of products ordered from largest to smallest')\n",
    "print(product_counts)\n",
    "print('\\nAnd a graph of what the curve looks like:')\n",
    "plt.plot(product_counts) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJTMKvYuZ9Zs"
   },
   "source": [
    "Wow! It looks like there are a few products that are purchased a lot. Let's take a look at those to see what they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0DhAue9MadsG",
    "outputId": "656f66b1-6fd6-442e-f176-c2cd9d6688a4"
   },
   "outputs": [],
   "source": [
    "df['product_id'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WcpOjstpjuYH",
    "outputId": "750a1770-956a-4526-99bc-9588b9ae37c0"
   },
   "outputs": [],
   "source": [
    "print(len(df['order_id'].unique()))\n",
    "print(len(df))\n",
    "# from collections import Counter\n",
    "# Counter(df['product_id'].value_counts().to_numpy())[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DiCRdyPEpWFA"
   },
   "source": [
    "This is a very extreme curve. It's unlikely that we will be able to use any products that don't appear in multiple orders. We can do a few more things to see how much usable data we have.\n",
    "\n",
    "First, we will tell value_counts to use percentages of the total instead of the sum values and divide the results equally into 10 bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BrmR_7Jgbahc",
    "outputId": "6742fb92-a0c4-44ae-fd77-876a36f17c65"
   },
   "outputs": [],
   "source": [
    "df['product_id'].value_counts(normalize=True, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "AYhSwxPR4C-Y",
    "outputId": "6abc32b1-d7e4-4ceb-e468-b905a3cffbcf"
   },
   "outputs": [],
   "source": [
    "df['price'].value_counts().sort_index().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "9qd6mg9t2-Ud",
    "outputId": "fae68a3d-58a0-4ae2-89f4-4ba7d21e8b1e"
   },
   "outputs": [],
   "source": [
    "totals = df.groupby(df.order_id)['price'].sum()\n",
    " \n",
    "totals.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wJQcYTmf5qWK",
    "outputId": "f5ae0b65-af03-4b10-ccf9-fb680a0d4456"
   },
   "outputs": [],
   "source": [
    "df['category_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UZ5Vv3x854cH",
    "outputId": "443047ff-15fe-419f-e102-4f5f67ae7e9e"
   },
   "outputs": [],
   "source": [
    "df['brand'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eAr75-G33l8o"
   },
   "source": [
    "Another thing we can do is compute the sparsity of the data. This is useful to see if there is enough overlap between the orders and products to make a useful decision for recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5aoGeTmPq55e",
    "outputId": "68bc7cdb-9005-4264-9407-3e8596f51f0d"
   },
   "outputs": [],
   "source": [
    "order_counts = df['order_id'].value_counts()\n",
    "num_orders = len(order_counts)\n",
    "num_items = len(product_counts)\n",
    "sparsity = 1 - len(df) / (num_orders * num_items)\n",
    "print(f'number of orders: {num_orders}, number of items: {num_items}')\n",
    "print(f'matrix sparsity: {sparsity:f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "To62Zd83tJ4f"
   },
   "source": [
    "Compare that with the 100k movielens dataset that has:\n",
    "\n",
    "```\n",
    "number of users: 943, number of items: 1682\n",
    "matrix sparsity: 0.936953\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pdnxBEmd4Pes"
   },
   "source": [
    "In addition to reducing the sparsity, another issue with this dataset is the greater number of items and orders. When I tried to re-use a notebook built for the 100k movielens dataset on this ecomerce data, it immediately ran out of memory when attempting to use the KNNBasic algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f7qa2oXpt2BI",
    "outputId": "a68977e0-6e52-4a3a-de9e-a1dc81be262b"
   },
   "outputs": [],
   "source": [
    "product = 943 * 1682\n",
    "print('Size for movielens: 'f'{product:,}')\n",
    " \n",
    "product = 1435266 * 25113\n",
    "print('Size for ecommerce dataset: 'f'{product:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NjTFgyUryB6E"
   },
   "source": [
    "This is a pretty clear reason why the in-memory recommendation approaches that work with movielens run out of memory when trying to apply them to the ecommerce dataset.\n",
    "\n",
    "We need to look at reducing the dataset into something both useful and manageable. To start with, we can remove any products that don't appear more than some value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ajDPMKaJ7OeA"
   },
   "outputs": [],
   "source": [
    "#@title Example form fields\n",
    "#@markdown Forms support many types of fields.\n",
    " \n",
    "filter_value = 1000  #@param {type: \"number\"}\n",
    "#@markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wQ5bYKJT50_n",
    "outputId": "49584c7e-148f-41fb-cea6-fcf5c2d7b0f6"
   },
   "outputs": [],
   "source": [
    "product_group = df.loc[:, ['order_id', 'product_id']].groupby('product_id').count()\n",
    " \n",
    "multi_product = product_group[product_group.order_id >= filter_value].count()\n",
    "single_product = product_group[product_group.order_id < filter_value].count()\n",
    " \n",
    "print('Products in at least',filter_value,'orders:',multi_product['order_id'])\n",
    "print('Products in less than',filter_value,'orders:',single_product['order_id'])\n",
    " \n",
    "# We can capture the list of mutiple product orders with this:\n",
    "product_filter = product_group[product_group.order_id >= filter_value].index.tolist()\n",
    " \n",
    "product_filtered_df = df[df['product_id'].isin(product_filter)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "khZ7bwJc6qS-"
   },
   "source": [
    "We can also remove orders that don't have more than some number of items.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TVIxIhDb_f8E"
   },
   "outputs": [],
   "source": [
    "#@title Example form fields\n",
    "#@markdown Forms support many types of fields.\n",
    " \n",
    "minimum_order_size =   3#@param {type: \"number\"}\n",
    "maximum_order_size =   20#@param {type: \"number\"}\n",
    " \n",
    "#@markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qZKx1mQYoUH9",
    "outputId": "996cf8cd-6446-4aef-bd21-37329c500d2d"
   },
   "outputs": [],
   "source": [
    "order_group = product_filtered_df.loc[:, ['order_id', 'product_id']].groupby('order_id').count()\n",
    " \n",
    "multi_order = order_group[(order_group.product_id >= minimum_order_size) & (order_group.product_id <= maximum_order_size)].count()\n",
    "single_order = order_group[(order_group.product_id < minimum_order_size) | (order_group.product_id > maximum_order_size)].count()\n",
    " \n",
    "print('Orders with at least',minimum_order_size,'products:',multi_order['product_id'])\n",
    "print('Orders with less than',minimum_order_size,'products:',single_order['product_id'])\n",
    " \n",
    "# We can capture the list of mutiple product orders with this:\n",
    "order_filter = order_group[(order_group.product_id >= minimum_order_size) & (order_group.product_id <= maximum_order_size)].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L42LelQPrcHl",
    "outputId": "3954ac42-00b0-478c-c9b6-b3dae71be194"
   },
   "outputs": [],
   "source": [
    "filtered_df = product_filtered_df[product_filtered_df['order_id'].isin(order_filter)].copy()\n",
    "print('Original dataframe length:', len(df))\n",
    "print('Filtered dataframe length:', len(filtered_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 371
    },
    "id": "yWQoVWQu8p_Y",
    "outputId": "3035200f-4db0-4155-f4ef-0e24d85748d3"
   },
   "outputs": [],
   "source": [
    "product_counts = filtered_df['product_id'].value_counts().to_numpy()\n",
    "print('There are', len(product_counts), 'unique products\\n')\n",
    "print('\\nAnd a graph of what the curve looks like:')\n",
    "plt.plot(product_counts) \n",
    "plt.show()\n",
    " \n",
    "order_counts = filtered_df['order_id'].value_counts()\n",
    "num_orders = len(order_counts)\n",
    "num_items = len(product_counts)\n",
    "sparsity = 1 - len(df) / (num_orders * num_items)\n",
    "print(f'number of orders: {num_orders}, number of items: {num_items}')\n",
    "print(f'matrix sparsity: {sparsity:f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N5-NsL0CieG1"
   },
   "outputs": [],
   "source": [
    "filtered_df['product_id'] = filtered_df['product_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bKFFtiTijwRw"
   },
   "outputs": [],
   "source": [
    "orderdf = filtered_df[['order_id', 'product_id']].sort_values('product_id').groupby('order_id').sum('product_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "rgUAGkHtnR2j",
    "outputId": "9a45aab4-e1b7-4024-9a9b-0f630996d7ec"
   },
   "outputs": [],
   "source": [
    "order_distro = orderdf['product_id'].value_counts().to_numpy()\n",
    "print('There are', len(order_distro), 'unique orders\\n')\n",
    "print('\\nAnd a graph of what the curve looks like:')\n",
    "plt.plot(order_distro) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IYUdUq8cW-fY"
   },
   "source": [
    "# Fun with Numbers\n",
    "\n",
    "The initial work I had done with this dataset used 1.0 as the \"rating\" for each product in an order. That turned out to be problematic because some algorithms multiple ratings as part of their score. And of course, this meant that a product \"rated\" once has the same score as a product \"rated\" 20 times.\n",
    "\n",
    "Changing this \"rating\" to a 5 seems to move past that issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YEcfGtLmAds_",
    "outputId": "c59017d2-8837-4808-88cf-a1645550655a"
   },
   "outputs": [],
   "source": [
    "filtered_df['rating'] = 5.0\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "id": "LXNnCGvPle4m",
    "outputId": "830b15f6-1573-4f4c-aaf6-b60e564c2c0e"
   },
   "outputs": [],
   "source": [
    "selected_df = filtered_df[['order_id', 'product_id', 'rating']].apply(pd.to_numeric, errors='coerce')\n",
    "selected_df.info()\n",
    "selected_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E55Bi-RgsbVZ"
   },
   "outputs": [],
   "source": [
    "def precision_recall_at_k(predictions, k=10, threshold=.75):\n",
    "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        # When n_rec_k is 0, Precision is undefined. We here set it to 0.\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        # When n_rel is 0, Recall is undefined. We here set it to 0.\n",
    "\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "\n",
    "    return precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aOSjX_t8gF1h"
   },
   "outputs": [],
   "source": [
    "def get_f_score(precision, recall):\n",
    "  denominator = precision + recall\n",
    "  if(denominator == 0):\n",
    "    return 0\n",
    "  return 2 * (precision * recall) / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jitg8F1Y2JIj",
    "outputId": "b914403a-9edd-4aae-c2a3-f6ebb9e107b5"
   },
   "outputs": [],
   "source": [
    "pip install implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df.head(5).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scipy.sparse.csr_matrix(selected_df.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499,
     "referenced_widgets": [
      "38caeadca406486e886e91666188a293",
      "4f3056d5f8c04857a846ef9ddaa81dc4",
      "45197b0116e749fa9cf06bcbf7b0a51f",
      "21357474e2bd4fe79c97f614f6a35190",
      "75422b249afb4908b8d2839c549798f6",
      "1e606ef7df03465cad86e5510b24b8d4",
      "bdd86311b117451586ebdc39a3a46ab9",
      "b2a09233af5e4ef3aeb217d69d644bb9"
     ]
    },
    "id": "uJxPJMTR2rfI",
    "outputId": "b6e937c0-fbcc-45b2-afd3-a1feefe9265f"
   },
   "outputs": [],
   "source": [
    " \n",
    "import implicit\n",
    "import scipy\n",
    " \n",
    "# initialize a model\n",
    "model = implicit.als.AlternatingLeastSquares(factors=50)\n",
    "\n",
    "# train the model on a sparse matrix of item/user/confidence weight\n",
    "sparse_product = scipy.sparse.csr_matrix(selected_df.values)\n",
    "model.fit(sparse_product)\n",
    "\n",
    "sparse_order = sparse_order.T.tocsr()\n",
    "# recommend items for a user\n",
    "# user_items = item_user_data.T.tocsr()\n",
    "# recommendations = model.recommend(userid=0, user_items=[0], recalculate_user=True)\n",
    " \n",
    "# # find related items\n",
    "# related = model.similar_items(3000)\n",
    "# print(related)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "related = model.similar_items(0)\n",
    "print(related)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.recommend(1, sparse_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implicit.datasets.lastfm import get_lastfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists, users, plays = get_lastfm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plays_scr = plays.tocsr()\n",
    "print(plays_scr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "seQ89SSOwXdE"
   },
   "source": [
    "# Surprise Install and Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QCbzte1Lq4et",
    "outputId": "fb33e936-72f6-46e2-f761-54a8b22c81c1"
   },
   "outputs": [],
   "source": [
    "!pip install surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y5XWiaXnrZXC"
   },
   "outputs": [],
   "source": [
    "from surprise import Reader, Dataset\n",
    "from surprise import SVD, KNNBasic\n",
    "from surprise.model_selection import cross_validate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yHMPPzm5wcIp"
   },
   "source": [
    "# Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sge-NUelq2Xt",
    "outputId": "d3f4b83e-f8f0-4a1c-a676-150d77f8e81e"
   },
   "outputs": [],
   "source": [
    "# A reader is still needed but only the rating_scale param is requiered.\n",
    "reader = Reader(rating_scale=(0.0, 5.0))\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "data = Dataset.load_from_df(filtered_df[['order_id', 'product_id', 'rating']], reader)\n",
    "\n",
    "filtered_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ougNsoJOfYp2",
    "outputId": "2ec889b7-ef14-411a-ea81-73f74eaa2611"
   },
   "outputs": [],
   "source": [
    "from surprise.model_selection import KFold\n",
    "from collections import defaultdict\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "# We'll use the famous SVD algorithm.\n",
    "algo = SVD()\n",
    "\n",
    "for trainset, testset in kf.split(data):\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=5, threshold=5)\n",
    "\n",
    "    # Precision and recall can then be averaged over all users\n",
    "    precision = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "    recall = sum(rec for rec in recalls.values()) / len(recalls)\n",
    "    fscore = get_f_score(precision, recall)\n",
    "    print('Precision:', precision, 'Recall:', recall, 'F1 Score', fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ss0dXmHs0gab"
   },
   "outputs": [],
   "source": [
    "## TODO - figure out what the scores would be if we simply recommended the most popular item\n",
    "\n",
    "## TODO - what happens if we remove duplicates - but no really, how the heck to we even do that?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwkRU9QFqlmX"
   },
   "source": [
    "\n",
    "Show probability that the recommendation was acted on 50%\n",
    "\n",
    "Assume that in the real world maybe 25%\n",
    "\n",
    "For 25%, calculate additional value that would have been added if this system was in place.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EhkgQR57pTGK",
    "outputId": "8f7941cc-1039-4157-9b26-abb8ffc28f0f"
   },
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "\n",
    "  uid = random.choice(order_filter)\n",
    "  iid = random.choice(product_filter)\n",
    "\n",
    "  print(algo.predict(uid, iid))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UyrhvNUX1Cez"
   },
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=10):\n",
    "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    \"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RHhz9YpIwVZE"
   },
   "outputs": [],
   "source": [
    "trainset = data.build_full_trainset()\n",
    "algo = SVD()\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Than predict ratings for all pairs (u, i) that are NOT in the training set.\n",
    "testset = trainset.build_anti_testset()\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "uid = random.choice(order_filter)\n",
    "\n",
    "top_n = get_top_n(predictions, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eu9moO_X1Z4h"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of ECommerce-recommendation",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
