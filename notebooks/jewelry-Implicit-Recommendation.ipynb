{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gEfZf48Wu5f0"
   },
   "source": [
    "![HSV-AI Logo](https://github.com/HSV-AI/hugo-website/blob/master/static/images/logo_v9.png?raw=true)\n",
    "\n",
    "# Implicit Recommendation from ECommerce Data\n",
    "\n",
    "Some of the material for this work is based on [A Gentle Introduction to Recommender Systems with Implicit Feedback](https://jessesw.com/Rec-System/) by Jesse Steinweg Woods. This tutorial includes an implementation of the Alternating Least Squares algorithm and some other useful functions (like the area under the curve calculation). Other parts of the tutorial are based on a previous version of the Implicit library and had to be reworked.\n",
    "\n",
    "The dataset used for this work is from Kaggle [Vipin Kumar Transaction Data](https://www.kaggle.com/vipin20/transaction-data):\n",
    "\n",
    "## Context\n",
    "\n",
    "This is a item purchased transactions data. It has 8 columns.\n",
    "This data makes you familer with transactions data.\n",
    "\n",
    "## Content\n",
    "\n",
    "Data description is :-\n",
    "\n",
    "* UserId -It is a unique ID for all User Id\n",
    "* TransactionId -It contains unique Transactions ID\n",
    "* TransactionTime -It contains Transaction Time\n",
    "* ItemCode -It contains item code that item will be purchased\n",
    "* ItemDescription -It contains Item description\n",
    "* NumberOfItemPurchased -It contains total number of items Purchased\n",
    "* CostPerltem -Cost per item Purchased\n",
    "* Country -Country where item purchased\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OApEEC0_wB4C"
   },
   "source": [
    "# Global Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fsb9emt6nrPu"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import implicit\n",
    "import scipy\n",
    "from sklearn import metrics\n",
    "from pandas.api.types import CategoricalDtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Common-Functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = pd.read_pickle('../data/interim/jewelry/transactions.gz')\n",
    "print('Loaded',len(transactions),'rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_list = list(np.sort(transactions.order_id.unique())) # Get our unique customers\n",
    "item_list = list(transactions.product_id.unique()) # Get our unique products that were purchased\n",
    "quantity_list = list(transactions.quantity) # All of our purchases\n",
    "\n",
    "cols = transactions.order_id.astype(CategoricalDtype(categories=transaction_list, ordered=True)).cat.codes \n",
    "# Get the associated row indices\n",
    "rows = transactions.product_id.astype(CategoricalDtype(categories=item_list, ordered=True)).cat.codes \n",
    "# Get the associated column indices\n",
    "purchases_sparse = scipy.sparse.csr_matrix((quantity_list, (rows, cols)), shape=(len(item_list), len(transaction_list)))\n",
    "\n",
    "total_count = len(transactions)\n",
    "denominator = len(transaction_list) * len(item_list)\n",
    "sparsity = 100*(1 - total_count*1.0/denominator)\n",
    "print(\"The transactions dataframe is \", \"%.4f\" % sparsity + \"% empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & Test Datasets\n",
    "\n",
    "We will use the function below to create a training and test dataset from the tutorial linked at the top. The test dataset masks some percentage of purchases to tested later with a recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_train, product_test, products_altered, transactions_altered = make_train(purchases_sparse, pct_test = 0.211)\n",
    "print('Total number of masked items:',product_test.count_nonzero()-product_train.count_nonzero())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implicit Recommendation Model\n",
    "\n",
    "The code below creates and trains one of the models available from the Implicit package. Currently using hyperparameters suggested by various tutorials with no tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 15\n",
    "factors = 64\n",
    "regularization = 0.003\n",
    "iterations = 50\n",
    "\n",
    "# model = implicit.als.AlternatingLeastSquares(factors=factors,\n",
    "#                                     regularization=regularization,\n",
    "#                                     iterations=iterations)\n",
    "\n",
    "## BayesianPersonalizedRanking was pretty bad\n",
    "model = implicit.bpr.BayesianPersonalizedRanking(factors=factors,\n",
    "                                     regularization=regularization,\n",
    "                                     iterations=iterations)\n",
    "\n",
    "\n",
    "# model = implicit.lmf.LogisticMatrixFactorization(factors=32,\n",
    "#                                     regularization=0.1,\n",
    "#                                     iterations=50)\n",
    "\n",
    "model.fit((product_train * alpha).astype('double'))\n",
    "\n",
    "user_vecs = model.user_factors\n",
    "item_vecs = model.item_factors\n",
    "\n",
    "# Deprecated function below\n",
    "# user_vecs, item_vecs = implicit.alternating_least_squares((product_train*alpha).astype('double'), \n",
    "#                                                           factors=32, \n",
    "#                                                           regularization = 0.1, \n",
    "#                                                           iterations = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/interim/jewelry/user_factors', user_vecs)\n",
    "np.save('../data/interim/jewelry/item_factors', item_vecs)\n",
    "np.save('../data/interim/jewelry/product_train', product_train*alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring the Model\n",
    "\n",
    "Following the tutorial, we will use the area under the Receiver Operating Characteristic curve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, popular = calc_mean_auc(product_train, products_altered, \n",
    "              [scipy.sparse.csr_matrix(item_vecs), scipy.sparse.csr_matrix(user_vecs.T)], product_test)\n",
    "\n",
    "\n",
    "print('Our model scored',test,'versus a score of',popular,'if we always recommended the most popular item.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spot Checking\n",
    "\n",
    "Now that we have a pretty good idea of the model performance overall, we can spot check a few things like finding similar items and checking item recommendations for an existing invoice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_lookup = transactions[['product_id', 'category_code']].drop_duplicates() # Only get unique item/description pairs\n",
    "item_lookup['product_id'] = item_lookup.product_id.astype(str) # Encode as strings for future lookup ease\n",
    "\n",
    "price_lookup = transactions[['product_id', 'price']].drop_duplicates() # Only get unique item/description pairs\n",
    "price_lookup['product_id'] = price_lookup.product_id.astype(str) # Encode as strings for future lookup ease\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "related = model.similar_items(1284)\n",
    "for rel in related:\n",
    "    index = rel[0]\n",
    "    prob = rel[1]\n",
    "    item = item_lookup[item_lookup.product_id == str(item_list[index])].values\n",
    "    print(prob, item[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_items = (product_train * alpha).astype('double').T.tocsr()\n",
    "def recommend(order):\n",
    "    print('Order Contents:')\n",
    "    print(transactions[transactions.order_id == transaction_list[order]].loc[:, ['product_id', 'category_code']])\n",
    "    print('Recommendations:')\n",
    "    recommendations = model.recommend(order, user_items)\n",
    "    for rec in recommendations:\n",
    "        index = rec[0]\n",
    "        prob = rec[1]\n",
    "        stock_code = item_list[index]\n",
    "        item = item_lookup[item_lookup.product_id == str(item_list[index])].values\n",
    "        print(prob, stock_code, item[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend(2200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions['ItemTotal'] = transactions['quantity'] * transactions['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_price = []\n",
    "for user in range(0, len(transaction_list)):\n",
    "    recommendations = model.recommend(user, user_items)\n",
    "    index = recommendations[0][0]\n",
    "    price = price_lookup[price_lookup.product_id == str(item_list[index])].values\n",
    "    item = item_lookup[item_lookup.product_id == str(item_list[index])].values\n",
    "    recommended_price.append(price[0][1])\n",
    "    \n",
    "total_recommended = np.sum(recommended_price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accept_rate = 0.3\n",
    "print('After recommending',len(transaction_list),'items with a',accept_rate,'acceptance rate, there would be an increase of',\n",
    "      \"${:,.2f}\".format(total_recommended*accept_rate),'in additional purchases.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totals = transactions.groupby(transactions.order_id)['ItemTotal'].sum()\n",
    "total = totals.sum()\n",
    "\n",
    "print('Added to the initial total of all',len(transaction_list),'purchases valued at',\n",
    "      \"${:,.2f}\".format(total),', the percentage increase in revenue would be', \"{:,.4f}%\".format(total_recommended*accept_rate / total * 100 ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of ECommerce-recommendation",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "productrec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
