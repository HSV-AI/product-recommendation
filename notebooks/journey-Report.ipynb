{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29b3e514",
   "metadata": {},
   "source": [
    "![HSV-AI Logo](https://github.com/HSV-AI/hugo-website/blob/master/static/images/logo_v9.png?raw=true)\n",
    "\n",
    "# Implicit Recommendation from Jewelry Data\n",
    "\n",
    "Some of the material for this work is based on [A Gentle Introduction to Recommender Systems with Implicit Feedback](https://jessesw.com/Rec-System/) by Jesse Steinweg Woods. This tutorial includes an implementation of the Alternating Least Squares algorithm and some other useful functions (like the area under the curve calculation). Other parts of the tutorial are based on a previous version of the Implicit library and had to be reworked.\n",
    "\n",
    "[Complete Journey Dataset](https://www.kaggle.com/frtgnn/dunnhumby-the-complete-journey)\n",
    "\n",
    "This dataset contains household level transactions over two years from a group of 2,500 households who are frequent shoppers at a retailer. It contains all of each householdâ€™s purchases, not just those from a limited number of categories. For certain households, demographic information as well as direct marketing contact history are included.\n",
    "\n",
    "\n",
    "## Basics of EDA\n",
    "\n",
    "Here are a few things that we are looking for in the invoice / transaction data:\n",
    "\n",
    "1. Were there any negative totals? If so why?\n",
    "2. What percentage of the purchases actually contained multiple items?\n",
    "3. What is the spread of purchases by customer ID? Do we have a few customers whose behavior may drive recommendations in a way that doesn't fit the average customer?\n",
    "4. Where there any purchases that were VERY large? If so why? Do we want to include these values to train model behavior?\n",
    "5. Is there any missing data that we need to scrub?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10316ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-21 05:20:21,484 - kedro.framework.session.store - INFO - `read()` not implemented for `BaseSessionStore`. Assuming empty store.\n",
      "2021-12-21 05:20:21,565 - root - INFO - ** Kedro project productrec\n",
      "2021-12-21 05:20:21,567 - root - INFO - Defined global variable `context`, `session` and `catalog`\n",
      "2021-12-21 05:20:21,585 - root - INFO - Registered line magic `run_viz`\n"
     ]
    }
   ],
   "source": [
    "%reload_kedro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84827ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import implicit\n",
    "import scipy\n",
    "from sklearn import metrics\n",
    "from pandas.api.types import CategoricalDtype\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce17187f",
   "metadata": {},
   "source": [
    "# Available Files\n",
    "\n",
    "Let's go ahead and look into some of these files and see what we can see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faa63da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-21 05:25:58,281 - kedro.io.data_catalog - INFO - Loading data from `journey_kaggle_transaction_data` (CSVDataSet)...\n",
      "2021-12-21 05:26:18,192 - kedro.io.data_catalog - INFO - Loading data from `journey_kaggle_product_data` (CSVDataSet)...\n",
      "   PRODUCT_ID  MANUFACTURER    DEPARTMENT     BRAND            COMMODITY_DESC  \\\n",
      "0       25671             2       GROCERY  National                  FRZN ICE   \n",
      "1       26081             2  MISC. TRANS.  National  NO COMMODITY DESCRIPTION   \n",
      "2       26093            69        PASTRY   Private                     BREAD   \n",
      "3       26190            69       GROCERY   Private      FRUIT - SHELF STABLE   \n",
      "4       26355            69       GROCERY   Private             COOKIES/CONES   \n",
      "\n",
      "            SUB_COMMODITY_DESC CURR_SIZE_OF_PRODUCT  \\\n",
      "0          ICE - CRUSHED/CUBED                22 LB   \n",
      "1  NO SUBCOMMODITY DESCRIPTION                        \n",
      "2         BREAD:ITALIAN/FRENCH                        \n",
      "3                  APPLE SAUCE                50 OZ   \n",
      "4            SPECIALTY COOKIES                14 OZ   \n",
      "\n",
      "                                                DESC  \n",
      "0                        FRZN ICEICE - CRUSHED/CUBED  \n",
      "1  NO COMMODITY DESCRIPTIONNO SUBCOMMODITY DESCRI...  \n",
      "2                          BREADBREAD:ITALIAN/FRENCH  \n",
      "3                    FRUIT - SHELF STABLEAPPLE SAUCE  \n",
      "4                     COOKIES/CONESSPECIALTY COOKIES  \n",
      "   household_key    BASKET_ID  DAY  PRODUCT_ID  QUANTITY  SALES_VALUE  \\\n",
      "0           2375  26984851472    1     1004906         1         1.39   \n",
      "1           2375  26984851472    1     1033142         1         0.82   \n",
      "2           2375  26984851472    1     1036325         1         0.99   \n",
      "3           2375  26984851472    1     1082185         1         1.21   \n",
      "4           2375  26984851472    1     8160430         1         1.50   \n",
      "\n",
      "   STORE_ID  RETAIL_DISC  TRANS_TIME  WEEK_NO  COUPON_DISC  COUPON_MATCH_DISC  \n",
      "0       364        -0.60        1631        1          0.0                0.0  \n",
      "1       364         0.00        1631        1          0.0                0.0  \n",
      "2       364        -0.30        1631        1          0.0                0.0  \n",
      "3       364         0.00        1631        1          0.0                0.0  \n",
      "4       364        -0.39        1631        1          0.0                0.0  \n"
     ]
    }
   ],
   "source": [
    "transactions = catalog.load(\"journey_kaggle_transaction_data\")\n",
    "\n",
    "products_df = catalog.load(\"journey_kaggle_product_data\")\n",
    "products_df['DESC'] = products_df['COMMODITY_DESC'] + products_df['SUB_COMMODITY_DESC']\n",
    "print(products_df.head())\n",
    "\n",
    "# transactions = pd.read_csv('../data/external/journey/transaction_data.csv')\n",
    "print(transactions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62785e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown as md\n",
    "\n",
    "order_count = len(pd.unique(transactions['BASKET_ID']))\n",
    "customer_count = len(pd.unique(transactions['household_key']))\n",
    "product_count = len(pd.unique(transactions[\"PRODUCT_ID\"]))\n",
    "\n",
    "md(\n",
    "'''\n",
    "# Overall Data Report\n",
    "\n",
    "The data consists of:\n",
    "* {} orders\n",
    "* {} customers\n",
    "* {} products\n",
    "\n",
    "'''.format(order_count, customer_count, product_count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38c33520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Installing collected packages: tabulate\n",
      "Successfully installed tabulate-0.8.9\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2ef8fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# Top 5 customers based on product count purchased:\n",
       "\n",
       "|   household_key |   household_key |\n",
       "|----------------:|----------------:|\n",
       "|             718 |            6851 |\n",
       "|            2459 |            6646 |\n",
       "|            1609 |            6625 |\n",
       "|            1111 |            6576 |\n",
       "|            1453 |            6561 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = '''\n",
    "# Top 5 customers based on product count purchased:\n",
    "\n",
    "'''\n",
    "\n",
    "user_counts = transactions.groupby(transactions.household_key)['household_key'].count().sort_values(ascending=False)\n",
    "five_total = 0\n",
    "for index, row in user_counts[:5].iteritems():\n",
    "    five_total += row\n",
    "\n",
    "table_str = user_counts[:5].to_markdown()\n",
    "\n",
    "output += table_str\n",
    "\n",
    "md(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ea47ce",
   "metadata": {},
   "source": [
    "# Checking for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4b7005",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total length is',len(transactions))\n",
    "transactions.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f14062",
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_counts = transactions['BASKET_ID'].value_counts().to_numpy()\n",
    "print('There are', len(transaction_counts), 'unique transactions\\n')\n",
    "print('Here are the counts of transactions ordered from largest to smallest')\n",
    "print(transaction_counts)\n",
    "print('\\nAnd a graph of what the curve looks like:')\n",
    "plt.plot(transaction_counts) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cc9676",
   "metadata": {},
   "source": [
    "# User Interactions\n",
    "\n",
    "Let's take a look at how many unique customers are included in this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c72075",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_counts = transactions['household_key'].value_counts().to_numpy()\n",
    "print('There are', len(user_counts), 'unique customers\\n')\n",
    "print('Here are the counts of transactions per customer ordered from largest to smallest')\n",
    "print(user_counts)\n",
    "print('\\nAnd a graph of what the curve looks like:')\n",
    "plt.plot(user_counts) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336e4d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.options.display.float_format = '{:.0f}'.format\n",
    "\n",
    "\n",
    "transactions.groupby(['household_key'])['household_key'] \\\n",
    "                             .count() \\\n",
    "                             .reset_index(name='count') \\\n",
    "                             .sort_values(['count'], ascending=False) \\\n",
    "                             .head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad28e4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions[transactions.household_key == 718].groupby(transactions.BASKET_ID).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ae31c7",
   "metadata": {},
   "source": [
    "It appears that there are a lot of different transactions, so probably not just the same thing being purchased over and over. Not really sure what to do with this at the moment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99236c27",
   "metadata": {},
   "source": [
    "# Transactions over Time\n",
    "\n",
    "Now we need to look at the number of items purchased each day to see if there is anything interesting that pops out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8683db",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.groupby(['DAY'])['DAY'] \\\n",
    "                             .count() \\\n",
    "                             .reset_index(name='count') \\\n",
    "                             .sort_values(['DAY'], ascending=True) \\\n",
    "                             .plot(x='DAY', y='count', figsize=(15,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcb3cca",
   "metadata": {},
   "source": [
    "# Checking Invoice Totals\n",
    "\n",
    "We need to make sure all the invoice totals that we're using are positive - this keeps us from using invoices that captured customer returned items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03139811",
   "metadata": {},
   "outputs": [],
   "source": [
    "totals = transactions.groupby(transactions.BASKET_ID)['SALES_VALUE'].sum()\n",
    "totals.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3455c176",
   "metadata": {},
   "outputs": [],
   "source": [
    "totals.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e450a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are', len(transactions[transactions.QUANTITY < 0]), 'negative quantities')\n",
    "transactions[transactions.QUANTITY < 0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35512baf",
   "metadata": {},
   "source": [
    "It looks like the negative quantities are driven by returned items. Let's see if anyone purchased and returned items in the same transaction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72b1edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = transactions.groupby(transactions.BASKET_ID).agg(minQ=('QUANTITY', 'min'), \n",
    "                               maxQ=('QUANTITY', 'max'))\n",
    "temp_df[(temp_df.minQ < 0) & (temp_df.maxQ > 0)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd30b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are', len(transactions[transactions.SALES_VALUE < 0]), 'negative prices')\n",
    "transactions[transactions.SALES_VALUE < 0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439e16a4",
   "metadata": {},
   "source": [
    "We can also check these transactions to see if there was a mix of negative prices along with positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309c0a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = transactions.groupby(transactions.BASKET_ID).agg(minQ=('SALES_VALUE', 'min'), \n",
    "                               maxQ=('SALES_VALUE', 'max'))\n",
    "temp_df[(temp_df.minQ < 0) & (temp_df.maxQ > 0)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf120355",
   "metadata": {},
   "source": [
    "Now that we have identified the cause of negative totals, we can remove them so that they do not affect our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c731b5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = transactions[(transactions.QUANTITY > 0) & (transactions.SALES_VALUE > 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73b2059",
   "metadata": {},
   "source": [
    "Now we can check the totals that were much higher than average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af21a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions[transactions.BASKET_ID == 32006114302].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4788c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(transactions[transactions.BASKET_ID == 32006114302])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ce2a40",
   "metadata": {},
   "source": [
    "It looks like there are two distinct cases where we may have an issue:\n",
    "\n",
    "1. Extremely high priced items\n",
    "2. Extremely high numbers of items purchased on the same transaction\n",
    "\n",
    "We can remove both of these by just keeping the values within the 98% quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33d42c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = transactions[\"SALES_VALUE\"].quantile(0.98)\n",
    "print(q)\n",
    "#transactions = transactions[transactions[\"price\"] < q]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ce7bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = transactions[\"QUANTITY\"].quantile(0.98)\n",
    "print(q)\n",
    "# transactions = transactions[transactions[\"quantity\"] < q]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d053d6e6",
   "metadata": {},
   "source": [
    "# Products Purchased Once\n",
    "\n",
    "Let's find products that were only purchased once and filter them out of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab376df",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_counts = transactions.groupby(transactions.PRODUCT_ID)['PRODUCT_ID'].count().sort_values(ascending=False).to_numpy()\n",
    "\n",
    "plt.plot(product_counts)\n",
    "plt.show()\n",
    "\n",
    "minimum_purchaces = 2\n",
    "product_group = transactions.loc[:, ['BASKET_ID', 'PRODUCT_ID']].groupby('PRODUCT_ID').count()\n",
    " \n",
    "multi_purchase = product_group[(product_group.BASKET_ID >= minimum_purchaces)].count()\n",
    "single_purchase = product_group[(product_group.BASKET_ID < minimum_purchaces)].count()\n",
    " \n",
    "print('Products with at least',minimum_purchaces,'purchase:',multi_purchase['BASKET_ID'])\n",
    "print('Products with less than',minimum_purchaces,'purchase:',single_purchase['BASKET_ID'])\n",
    " \n",
    "# We can capture the list of mutiple product orders with this:\n",
    "product_filter = product_group[(product_group.BASKET_ID >= minimum_purchaces)].index.tolist()\n",
    "\n",
    "filtered_df = transactions[transactions['PRODUCT_ID'].isin(product_filter)].copy()\n",
    "\n",
    "print('Original dataframe length:', len(transactions))\n",
    "print('Filtered dataframe length:', len(filtered_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f60d387",
   "metadata": {},
   "source": [
    "# Orders with a single item\n",
    "\n",
    "We will need to remove transactions that only included a single item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a86af26",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_order_size = 2\n",
    "order_group = filtered_df.loc[:, ['BASKET_ID', 'PRODUCT_ID']].groupby('BASKET_ID').count()\n",
    " \n",
    "multi_order = order_group[(order_group.PRODUCT_ID >= minimum_order_size)].count()\n",
    "single_order = order_group[(order_group.PRODUCT_ID < minimum_order_size)].count()\n",
    " \n",
    "print('Orders with at least',minimum_order_size,'products:',multi_order['PRODUCT_ID'])\n",
    "print('Orders with less than',minimum_order_size,'products:',single_order['PRODUCT_ID'])\n",
    " \n",
    "# We can capture the list of mutiple product orders with this:\n",
    "order_filter = order_group[(order_group.PRODUCT_ID >= minimum_order_size)].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9308b48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filtered_df[filtered_df['BASKET_ID'].isin(order_filter)].copy()\n",
    "\n",
    "print('Original dataframe length:', len(transactions))\n",
    "print('Filtered dataframe length:', len(filtered_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d0cd2c",
   "metadata": {},
   "source": [
    "# Returning Customers\n",
    "\n",
    "We may also want to remove single visit customers. This is something to try and see if it reduces the sparcity. We may also want to remove users that make a much larger number of purchases than the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bd4d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_counts = transactions.groupby(transactions.household_key)['household_key'].count().sort_values(ascending=False).to_numpy()\n",
    "\n",
    "plt.plot(user_counts)\n",
    "plt.show()\n",
    "\n",
    "minimum_purchaces = 2\n",
    "user_group = transactions.loc[:, ['BASKET_ID', 'household_key']].groupby('household_key').count()\n",
    " \n",
    "multi_purchase = user_group[(user_group.BASKET_ID >= minimum_purchaces)].count()\n",
    "single_purchase = user_group[(user_group.BASKET_ID < minimum_purchaces)].count()\n",
    " \n",
    "print('Users with at least',minimum_order_size,'purchase:',multi_purchase['BASKET_ID'])\n",
    "print('Users with less than',minimum_order_size,'purchase:',single_purchase['BASKET_ID'])\n",
    " \n",
    "# We can capture the list of mutiple product orders with this:\n",
    "user_filter = user_group[(user_group.BASKET_ID >= minimum_order_size)].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51beef6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filtered_df[filtered_df['household_key'].isin(user_filter)].copy()\n",
    "\n",
    "print('Original dataframe length:', len(transactions))\n",
    "print('Filtered dataframe length:', len(filtered_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d924b319",
   "metadata": {},
   "source": [
    "# Data Sparcity\n",
    "\n",
    "Let's take a look at the sparcity of the data. This will tell us how many products were purchased across multiple orders. This is directly related to how well a recommendation system can be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8f80fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_list = list(np.sort(filtered_df.BASKET_ID.unique())) # Get our unique customers\n",
    "item_list = list(filtered_df.PRODUCT_ID.unique()) # Get our unique products that were purchased\n",
    "quantity_list = list(filtered_df.QUANTITY) # All of our purchases\n",
    "\n",
    "cols = filtered_df.BASKET_ID.astype(CategoricalDtype(categories=transaction_list, ordered=True)).cat.codes \n",
    "# Get the associated row indices\n",
    "rows = filtered_df.PRODUCT_ID.astype(CategoricalDtype(categories=item_list, ordered=True)).cat.codes \n",
    "# Get the associated column indices\n",
    "purchases_sparse = scipy.sparse.csr_matrix((quantity_list, (rows, cols)), shape=(len(item_list), len(transaction_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00f83fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_size = purchases_sparse.shape[0]*purchases_sparse.shape[1] # Number of possible interactions in the matrix\n",
    "num_purchases = len(purchases_sparse.nonzero()[0]) # Number of items interacted with\n",
    "sparsity = 100*(1 - (num_purchases/matrix_size))\n",
    "sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab54dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plt.spy(purchases_sparse, markersize=1, aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d867a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filtered_df.rename(columns={\"PRODUCT_ID\": \"product_id\", \"QUANTITY\": \"quantity\", \"BASKET_ID\": \"order_id\", \"SALES_VALUE\": \"price\"})\n",
    "final_df = filtered_df[[\"order_id\", \"product_id\", \"quantity\", \"price\"]]\n",
    "products_df = products_df.rename(columns={\"PRODUCT_ID\":\"product_id\", \"DESC\":\"description\"})[[\"product_id\", \"description\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67c70a1",
   "metadata": {},
   "source": [
    "# Storing Interim Data\n",
    "\n",
    "Now that we have the data cleaned up a bit and formatted correctly, we can save it to an interim file to be picked up by the model training algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1b3e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.save(\"journey_transactions\", final_df)\n",
    "catalog.save(\"journey_products\", products_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed52baa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "productrec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
